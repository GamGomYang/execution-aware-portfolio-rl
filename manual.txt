========================
MPRL 프로젝트 매뉴얼
========================

1. 개요
-------
본 저장소는 Dow30 자산군을 대상으로 하는 Metaplastic Portfolio Reinforcement Learning(MPRL) 에이전트를 구현합니다. 핵심 구성요소:

- ``mprl/agent.py``: 자산/섹터 Dirichlet 정책, 더블 크리틱, 위험(메타플라스틱) 모듈
- ``mprl/env_real.py``: 야후 파이낸스 데이터를 재생하는 실제 환경
- ``mprl/trainer.py``: 학습 루프, 리플레이 버퍼, 의사결정 로깅
- ``mprl/eval.py`` 와 ``mprl/backtest.py``: 학습된 정책 평가 및 백테스트


2. 필수 소프트웨어 및 설치
--------------------------
Python 3.10+ 권장. 의존성은 ``requirements.txt`` 참고.

.. code-block:: bash

   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt

GPU 사용 시 ``torch``는 CUDA가 포함된 wheel로 별도 설치하세요.


3. 데이터 준비
--------------
``mprl/data_pipeline.py``가 yfinance에서 지수, 섹터 ETF, 매크로 지표를 내려받고 ``data/``에 캐시합니다.

.. code-block:: bash

   python3 -m mprl.data_pipeline   # 기본 파라미터(2018~2023, 1d) 예시

평가/학습에 필요한 기간만큼 ``--start``, ``--end`` 인자를 조정해 ``.npz`` 캐시를 생성할 수 있습니다. 인증 문제 발생 시 ``mprl/cacert.pem``을 통해 루트 인증서가 설정됩니다.


4. 학습 실행
------------
``mprl/trainer.py``의 ``run_training``을 CLI로 호출하거나 모듈 내 함수를 사용합니다.

.. code-block:: bash

   python3 -m mprl.trainer \
       --steps 3000 \
       --env-type real \
       --start 2013-01-01 \
       --end 2020-12-31 \
       --data-dir data \
       --log-dir logs/train_2013_2020 \
       --checkpoint models/mprl_2013_2020.pt

주요 옵션

- ``--env-type``: ``real``은 실제 시장 데이터, 기본값 ``stub``는 난수 기반 모의 환경
- ``--steps``: 학습 스텝 수(디폴트 512)
- ``--checkpoint``: 학습 종료 후 정책 저장 경로

학습 중 ``logs/.../decisions.jsonl``에 행동 이력, ``mprl.log``에 손실 스탯이 기록됩니다.


5. 평가 & 백테스트
-------------------
1) 정책 로드 후 평가 롤아웃:

.. code-block:: bash

   python3 -m mprl.eval \
       --start 2021-01-01 \
       --end 2024-12-31 \
       --data-dir data \
       --log-dir logs/eval_2021_2024 \
       --checkpoint models/mprl_2013_2020.pt \
       --report

``--deterministic`` 로 정책을 결정적으로 실행할 수 있고, ``--no-cache`` 로 데이터 재다운로드를 강제할 수 있습니다.
평가 모드는 어디까지나 저장된 체크포인트를 재생(replay)하는 용도라 ``logs/eval_*`` 만 생성되며, 학습 로그(``logs/train_*``)나 새로운 체크포인트는 만들어지지 않습니다. 학습을 다시 돌리고 싶으면 반드시 ``python3 -m mprl.trainer ...`` 명령을 사용해야 합니다.

2) ``logs/.../decisions.jsonl``을 사용한 백테스트:

.. code-block:: bash

   python3 -m mprl.backtest \
       --start 2021-01-01 \
       --end 2024-12-31 \
       --log-path logs/eval_2021_2024/decisions.jsonl

출력되는 메트릭: 총수익률, CAGR, 변동성, MDD, Sharpe/Sortino/Calmar, CVaR, 월간 다운사이드, 회전율, 리밸런싱 빈도 등.


6. 결과 시각화
--------------
``result_visualization.py``는 평가 로그에서 종목별 가중치 분포, 회전율, 공분산 히트맵을 그립니다.

.. code-block:: bash

   python3 result_visualization.py

그래프는 Matplotlib 윈도우로 표시되며, 필요 시 스크립트를 수정해 PNG 저장도 가능합니다.


7. 로그 구조
------------
``logs/<run>/mprl.log``: 학습/평가 진행 상황

``logs/<run>/decisions.jsonl``: 각 스텝별

- ``date``: yyyy-mm-dd
- ``action``: 30개 종목 비중
- ``reward`` / ``risk_metric`` / ``stress_signal``
- ``beta``: 위험 모듈 출력
- ``plasticity``: 플라스틱성 컨트롤러 상태
- ``explanations``: 위험 특징 상위 5개 값

``logs/<run>/raw_features.jsonl``: NaN/zero 벡터 등 이상 징후가 감지된 스텝의 원시 위험 피처 스냅샷. 스트레스 신호·beta·risk vector를 그대로 덤프하므로 피처 파이프라인(rolling, ffill, median 필터 등) 동작을 진단할 때 활용하세요.

결정 로그는 시간 순서를 유지해야만 백테스트/시각화 도구가 정상 작동합니다. ``scripts/normalize_decisions.py``를 사용하면

.. code-block:: bash

   python3 scripts/normalize_decisions.py logs/train_2013_2020/decisions.jsonl \
       --sorted-output logs/train_2013_2020/decisions_sorted.jsonl \
       --report logs/train_2013_2020/timeline_report.txt

처럼 정렬본(JSONL)과 타임라인 리포트를 동시에 얻을 수 있습니다. 정렬본이 존재하면 ``mprl.backtest``와 ``result_visualization.py`` 등은 자동으로 ``*_sorted.jsonl``을 우선 읽습니다. 원본은 보존되므로 필요 시 다시 정규화 과정을 반복해 최신 리포트/정렬본을 만들어 주세요.

전체 워크플로 예시

1. 데이터 캐시 생성

   .. code-block:: bash

      python3 -m mprl.data_pipeline \
          --start 2013-01-01 \
          --end 2024-12-31 \
          --data-dir data

2. 학습 실행 및 체크포인트 저장

   .. code-block:: bash

      python3 -m mprl.trainer \
          --steps 3000 \
          --env-type real \
          --start 2013-01-01 \
          --end 2020-12-31 \
          --data-dir data \
          --log-dir logs/train_2013_2020 \
          --checkpoint models/mprl_2013_2020.pt

3. 학습 로그 정렬/리포트

   .. code-block:: bash

      python3 scripts/normalize_decisions.py logs/train_2013_2020/decisions.jsonl \
          --sorted-output logs/train_2013_2020/decisions_sorted.jsonl \
          --report logs/train_2013_2020/timeline_report.txt

4. 체크포인트 평가(결정 로그 생성)

   .. code-block:: bash

      python3 -m mprl.eval \
          --start 2021-01-01 \
          --end 2024-12-31 \
          --data-dir data \
          --log-dir logs/eval_2021_2024 \
          --checkpoint models/mprl_2013_2020.pt

5. 평가 로그 정렬/리포트

   .. code-block:: bash

      python3 scripts/normalize_decisions.py logs/eval_2021_2024/decisions.jsonl \
          --sorted-output logs/eval_2021_2024/decisions_sorted.jsonl \
          --report logs/eval_2021_2024/timeline_report.txt

6. 백테스트(정렬본 자동 사용)

   .. code-block:: bash

      python3 -m mprl.backtest \
          --start 2021-01-01 \
          --end 2024-12-31 \
          --log-path logs/eval_2021_2024/decisions.jsonl

7. 시각화/진단

   .. code-block:: bash

      python3 result_visualization.py

각 단계는 결과물이 생성된 후 언제든 반복 가능하며, 정렬 스크립트를 다시 돌려도 원본 decisions.jsonl은 유지됩니다.

8. 자주 묻는 문제
-----------------
*Torch ImportError*  
시스템에 Torch 미설치 → ``pip install torch --index-url https://download.pytorch.org/whl/cu121`` 와 같이 환경에 맞는 wheel 설치.

*yfinance 다운로드 실패*  
- 네트워크/인증 문제 시 ``mprl/data_pipeline.py`` 내 SSL 설정이 제대로 되었는지 확인  
- 빈 데이터가 캐시되면 ``data/mprl_...npz`` 삭제 후 재실행

*결과 재현성*  
난수 시드 세팅은 현재 구현되어 있지 않습니다. 재현이 필요하다면 ``torch.manual_seed``, ``np.random.seed`` 등을 ``trainer.py``에 추가하세요.

*성능 튜닝*  
- 환경: ``transaction_cost``, ``max_weight_change`` 등 ``TrainingConfig`` 파라미터를 조정  
- 위험 모듈: ``homeostat_target``, ``risk_lambda`` 조절  
- 데이터: ``FeatureConfig.lookback`` 변경으로 상태 차원과 메모리 요구가 변합니다.


9. 파일 구조 요약
------------------
- ``mprl/``: 핵심 파이썬 모듈(환경, 에이전트, 네트워크, 데이터 파이프라인 등)
- ``models/``: 체크포인트(예: ``mprl_2013_2020.pt``)
- ``data/``: yfinance 캐시(.npz)
- ``logs/``: 학습/평가 로그, 결정 기록
- ``result_visualization.py``: 분석 스크립트

질문이나 버그는 issue 트래킹 시스템(또는 담당자)에 공유해 주세요.
